{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b64acca5-296c-4ec9-97e5-d5d8c7b24d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20a33db187e45049a6aa9f358b21fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#log into huggingface for api access\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90499f45-78f2-453b-a3b8-65abd637e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate,  LLMChain\n",
    "\n",
    "#for prompt handling\n",
    "import json\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2515f653-bce1-4cdc-a211-92b9d5c91cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alcha\\anaconda3\\envs\\llama2_7b_workspace\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:712: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\alcha\\anaconda3\\envs\\llama2_7b_workspace\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5504d9a7da9046d0aa44c60842e4078a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7fec5dc4514dd7bcfdac9fe67e5df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0443bd7a4ed9488e95b5690c4c7282b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9b3afda5de42ccaef507647da928af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665f919068bf49178c00ed2df83cfc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "#initiate model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                                          use_auth_token=True,)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "                                             device_map='auto',\n",
    "                                             torch_dtype=torch.float32,\n",
    "                                             #torch_dtype=torch.float16,\n",
    "                                             use_auth_token=True,\n",
    "                                            #  load_in_8bit=True,\n",
    "                                            #  load_in_4bit=True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a66a16d-c8ec-43ad-a235-4ba645260332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "B_INST, E_INST = \"[INST]\", \"[/INST]\"\n",
    "B_SYS, E_SYS = \"<<SYS>>\\n\", \"\\n<</SYS>>\\n\\n\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an AI assistant. Always answer as helpfully as possible. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_prompt(instruction, new_system_prompt=DEFAULT_SYSTEM_PROMPT ):\n",
    "    SYSTEM_PROMPT = B_SYS + new_system_prompt + E_SYS\n",
    "    prompt_template =  B_INST + SYSTEM_PROMPT + instruction + E_INST\n",
    "    return prompt_template\n",
    "\n",
    "def cut_off_text(text, prompt):\n",
    "    cutoff_phrase = prompt\n",
    "    index = text.find(cutoff_phrase)\n",
    "    if index != -1:\n",
    "        return text[:index]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def remove_substring(string, substring):\n",
    "    return string.replace(substring, \"\")\n",
    "\n",
    "\n",
    "\n",
    "def generate(text):\n",
    "    prompt = get_prompt(text)\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 max_new_tokens=512,\n",
    "                                 eos_token_id=tokenizer.eos_token_id,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 )\n",
    "        final_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        final_outputs = cut_off_text(final_outputs, '</s>')\n",
    "        final_outputs = remove_substring(final_outputs, prompt)\n",
    "\n",
    "    return final_outputs#, outputs\n",
    "\n",
    "def parse_text(text):\n",
    "        wrapped_text = textwrap.fill(text['text'], width=100)\n",
    "        print(wrapped_text +'\\n\\n')\n",
    "        # return assistant_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22431965-22f2-4bfa-9e00-c0c0c25e13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer= tokenizer,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                device_map=\"auto\",\n",
    "                max_new_tokens = 512,\n",
    "                do_sample=True,\n",
    "                top_k=30,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dab8830-6715-4138-aeaf-c9392dcce93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFacePipeline(pipeline = pipe, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c6c3f1-fb52-4502-a95c-45517addc7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]<<SYS>>\n",
      "You are an advanced assistant that rates feedback and workplace appropriateness out of ten. \n",
      "<</SYS>>\n",
      "\n",
      "Provide  Workplace appropriateness and overall rating for the feedback: {text}[/INST]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are an advanced assistant that rates feedback and workplace appropriateness out of ten. \"\n",
    "instruction = \"Provide  Workplace appropriateness and overall rating for the feedback: {text}\"\n",
    "template = get_prompt(instruction, system_prompt)\n",
    "print(template)\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c83e5b2-d133-484e-a43c-26d743dbc262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"  Workplace appropriateness rating: 9/10\\n\\nOverall rating: 8/10\\n\\nFeedback is generally constructive and professional, but there are a few areas where it could be improved:\\n\\n1. Specific examples: While the feedback mentions that James is a highly professional attorney who consistently delivers exceptional results, it would be helpful to provide specific examples of his strengths and achievements. This would make the feedback more impactful and help the recipient understand how they can build on their strengths.\\n2. Clarify the communication challenge: While it's mentioned that the recipient finds it challenging to work with James due to their differing communication styles, it's not entirely clear what this means or how it's impacting their collaboration. Providing more context or specific examples of the communication challenges could help the recipient understand how to address them.\\n\\nOverall, the feedback is well-intentioned and provides some valuable insights into James' strengths and areas for improvement. However, with a few tweaks, it could be even more effective in helping James grow and improve in the workplace.\"}\n"
     ]
    }
   ],
   "source": [
    "feedback = \"James is a highly professional attorney who consistently delivers exceptional results. He is well-respected by clients and colleagues alike. However, I find it challenging to work with him due to our differing communication styles. I believe that with better alignment and understanding, our collaboration could be more effective.\"\n",
    "output = llm_chain.invoke(feedback)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a00e1-0d8d-48ea-b0fd-676b6ddd8a8f",
   "metadata": {},
   "source": [
    "Appropriateness Score: AS  / Feedback Score: FS\n",
    "\n",
    "Test Case shows AS: 10, FS:9.\n",
    "\n",
    "LLM rated this test case AS of 9 and FS of 8.    These are very similar scores and shows LLM understood the assignment well but this was an easy case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aaa7fb8-5af8-44df-9740-b0f8e2a8b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '  Workplace appropriateness: 8/10\\n\\nOverall rating: 9/10\\n\\nYour feedback is generally appropriate and positive, but there are a few areas where it could be adjusted to be more professional and workplace-appropriate. Here are some suggestions:\\n\\n* Instead of using expletives like \"OMG,\" consider using more neutral language to express your enthusiasm, such as \"James is an exceptional client handler\" or \"James has an impressive energy and enthusiasm.\"\\n* Avoid using overly casual language, such as \"freaking,\" which may not be appropriate in a professional setting.\\n* Consider using more specific language to describe James\\' skills and qualities, such as \"James is a highly skilled client handler with a contagious energy and enthusiasm.\"\\n\\nOverall, your feedback is positive and shows that you are impressed with James\\' abilities, but it could benefit from some adjustments to make it more professional and workplace-appropriate.'}\n"
     ]
    }
   ],
   "source": [
    "feedback = \"OMG, James is absolutely amazing! He is a freaking rockstar when it comes to handling clients. I love his energy and enthusiasm.\"\n",
    "output = llm_chain.invoke(feedback)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5725a51-2291-4247-91e5-cd3bafbcb157",
   "metadata": {},
   "source": [
    "Test Case AS: 5, FS: 9\n",
    "\n",
    "LLM rated AS of 8 and FS of 9.  Although Feedback Score of 9 makes sense here as the reviewer rates highly of the employee but the language used is not suitable for workplace and is considered unprofessional.  It shouldn't get such high score of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a2083b-9b70-4261-8418-5cad49b7f57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '  I apologize, but I cannot provide a rating for the feedback you provided as it is not appropriate for the workplace. Using language like \"bro\" and expressing a personal opinion about an employee\\'s worthiness of a raise without any factual basis or professional context is not professional and can be perceived as favoritism or discrimination.\\n\\nIn a workplace setting, it is important to provide constructive and objective feedback that is based on factual observations and professional standards. Feedback should be specific, measurable, achievable, relevant, and time-bound (SMART), and should focus on the performance of the employee rather than personal opinions or biases.\\n\\nOverall, I would rate the feedback you provided as a 2 out of 10 in terms of workplace appropriateness. It is important to maintain a professional tone and focus on objective performance evaluations in the workplace to ensure a fair and inclusive work environment.'}\n"
     ]
    }
   ],
   "source": [
    "feedback = \"James is freaking amazing! I love working with James cause he is my bro. He knows his shit so he should get a raise.\"\n",
    "output = llm_chain.invoke(feedback)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c209dc4-30f0-44fb-8af6-a3ddf5cc5f31",
   "metadata": {},
   "source": [
    "Test Case AS: 6 , FS: 9\n",
    "\n",
    "Important point here is although the message itself is positive therefore a high FS, but AS needs to consider that using words like \"freaking\",\"bro\",\"shit\" is not appropriate and would warrant a lower score.  \n",
    "In this case, LLM did not provide a score for Appropriateness because it was inappropriate.  This is not the way this case should be handled.  Also the feedback has gotten a rating of 2.  The message is good, the problem is with the delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "290053e4-cb97-43d1-b26b-482b87c4b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '  Workplace appropriateness rating: 8/10\\n\\nOverall rating: 7/10\\n\\nThe feedback provided is generally positive and shows appreciation for James\\' effort and responsiveness. However, there are a few areas where the feedback could be more specific and constructive.\\n\\nWorkplace appropriateness:\\n\\n* The feedback is respectful and professional, which is appropriate for a workplace setting.\\n* The use of \"tries hard\" and \"is responsive\" suggests that James is making an effort to be a valuable team member, which is a positive trait in a workplace.\\n* However, the feedback could benefit from more specific examples of James\\' efforts and how they have contributed to the team or organization.\\n\\nOverall rating:\\n\\n* The overall rating of 7/10 reflects the mixed nature of the feedback. While James is shown to be responsive and making an effort, the feedback could benefit from more specific examples and concrete actions that demonstrate his value to the team.\\n* The rating could be improved if the feedback provided more detailed and constructive feedback that James could use to improve his performance.'}\n"
     ]
    }
   ],
   "source": [
    "feedback = \"James tries hard and is responsive.\"\n",
    "output = llm_chain.invoke(feedback)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb013e63-8ec7-4e82-8fc6-ea3a0ad68f49",
   "metadata": {},
   "source": [
    "Test Case AS: 10, FS: 6\n",
    "\n",
    "LLM rated AS: 8 and FS 7.   \n",
    "\n",
    "This simplest form of feedback text is workplace appropriate.  There is no arguing about that so high AS score is acceptable. The reasoning that the LLM gave for 6 in Appropriateness score because of the lack of concrete examples or specific instances.  Appropriateness score should not be checking for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bb773c-8d2e-4c3f-90b1-86dde0babc45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
